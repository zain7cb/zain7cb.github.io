\documentclass{article}

\usepackage{amsmath, amsthm, amssymb, amsfonts}
\usepackage{thmtools}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{geometry}
\usepackage{float}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{framed}
\usepackage[dvipsnames]{xcolor}
\usepackage{tcolorbox}
\usepackage{physics}
\DeclareMathOperator{\grd}{grad}
\colorlet{LightGray}{White!90!Periwinkle}
\colorlet{LightOrange}{Orange!15}
\colorlet{LightGreen}{Green!15}

\newcommand{\HRule}[1]{\rule{\linewidth}{#1}}

\declaretheoremstyle[name=Theorem,]{thmsty}
\declaretheorem[style=thmsty,numberwithin=section]{theorem}
\tcolorboxenvironment{theorem}{colback=LightGray}

\declaretheoremstyle[name=Proposition,]{prosty}
\declaretheorem[style=prosty,numberlike=theorem]{proposition}
\tcolorboxenvironment{proposition}{colback=LightOrange}

\declaretheoremstyle[name=Principle,]{prcpsty}
\declaretheorem[style=prcpsty,numberlike=theorem]{principle}
\tcolorboxenvironment{principle}{colback=LightGreen}

\setstretch{1.2}
\geometry{
    textheight=9in,
    textwidth=5.5in,
    top=1in,
    headheight=12pt,
    headsep=25pt,
    footskip=30pt
}

% ------------------------------------------------------------------------------

\begin{document}

% ------------------------------------------------------------------------------
% Cover Page and ToC
% ------------------------------------------------------------------------------
\section*{Conservation of Energy}
Let $U \subset \mathbb{R}^n$ be an open set. A \textbf{vector field} $F$ on $U$ is a map 
$F: U \to \mathbb{R}^n$. So $F$ maps points to vectors with the same dimension. 
One thinks of vectors fields as a field of arrows attached to each point of $U$. 

A very simple example of a vector field is the gravitational field 
\[G(x,y,z) = (0,0,-g).\]
This is really an approximation of the field if we're close enough to 
Earth's surface. One imagines a bunch of arrows pointing downward. 
If we introduce a point mass $m$ into the
field, the mass feels a force of $mG = (0,0,-gm)$. 

If $F$ is a vector field and there exists some (scalar-valued) function $f$ such that
\[\grd f = F\]
then $f$ is said to be \textbf{conservative}. The function $f$ is called a \textbf{potential} function
for $F$. For technical reasons in physics, sometimes the definition uses
$-\grd f$ instead, and we note that $-\grd f = \grd(-f)$, so there's no real difference.

Suppose a particle of mass $m$ moves in $U$ on which a field of forces $F: U \to \mathbb{R}^3$ is defined.
That is, $F(x,y,z)$ is the force the particle is experiencing if it is positioned at $(x,y,z)$.
Let $C(t)$ be a parametrization of the particle's path. Then Newton's law says that the force acting on the 
particle is equal to the mass times its acceleration:
\[F(C(t)) = mC''(t).\]

The \textbf{kinetic energy} of a particle is 
\[\frac{1}{2} m \norm{C'(t)}^2.\]

\textbf{Conservation Law.} Suppose that $F$ is a conservative vector field and $\psi$ satisfies
$F = -\grd \psi$. That is, $\psi$ is the potential energy of the system. Suppose a particle of mass $m$ moves 
(according to Newton's law) where this field is defined and that the field is the only force acting on the particle. 
Then the sum of potential and kinetic energy is constant.

We differentiate
\[ \psi(C(t)) +  \frac{1}{2} m \norm{C'(t)}^2\]
with respect to $t$ to obtain 
\[ \grd\psi(C(t))\cdot C'(t) + m C'(t) \cdot C''(t). \]
Applying Newton's law, this becomes
\[ \grd\psi(C(t))\cdot C'(t) + C'(t) \cdot F(C(t)). \]
Finally, using $F = -\grd \psi$, we see these terms cancel each other out.

\section*{Potential Functions}

So far, we have seen scalar-valued functions, curves in space, and vector fields. Do not confuse these notions, warns
Lang.

Are potentials unique? The role of a potential is somewhat similar to the role of an antiderivative
in single variable calculus. There we learned an antiderivative is unique up to a constant. That is,
if $F$ and $G$ are two antiderivatives of $f$, then $F = G + C$ for some constant $C$. Well, there's a 
slight technicality. Consider the following functions 
\[g(x) = 1/x\]
and
\[f(x) = \begin{cases}
    1/x + 2,\ x>0\\
    1/x - 3,\ x<0.
\end{cases}\]
Then $f$ and $g$ have the same derivative, but they do not differ by a constant. The issue here is that
the domain of $f$ and $g$, which is $\mathbb{R} \setminus \{0\}$, is not \textbf{connected}.
So the more precise statement is that antiderivatives are unique up to a constant when the domain is connected.

The definition we'll take is the following: an open subset $U \subset \mathbb{R}^n$ is \textbf{connected} if 
between any two points in $U$, there is a differentiable path that joins them. More precisely,
if $P$ and $Q$ lie in $U$, then there is a differentiable curve $X(t)$ such that $X(t_0) = P$ and
$X(t_1) = Q$ for some $t_0,t_1$.

\textbf{Theorem.} If $U$ is an open connected subset of $\mathbb{R}^n$ and $f,g$ are differentiable with 
$\grd f(X) = \grd g(X)$ for each $X \in U$, then there exists a constant $k$ such that 
\[f(X) = g(X) + k\]
for all $X \in U$.

To prove this, let $\varphi(X) = f(X) - g(X)$. Then $\grd \varphi (X) = 0$ for all $X \in U$. Now let
$P,Q \in U$. There is some differentiable curve $X(t)$ connecting $P$ to $Q$. On the other hand,
\[\frac{d}{dt} \varphi(X(t)) = \grd\varphi(X(t))\cdot X'(t).\]
But $\grd \varphi (X) = 0$ for all $X \in U$. Thus this derivative is $0$, meaning $\varphi$ is constant
on the path $X(t)$, which implies $\varphi(P) = \varphi(Q)$. This means $\varphi$ is constant on $U$.

In the two variable case, a vector field takes the form 
\[F(x,y) = (f(x,y), g(x,y)).\]
A potential function $\varphi$ would then (by definition) satisfy the equations
\[\frac{\partial \varphi}{\partial x} = f,\ \frac{\partial \varphi}{\partial y} = g.\]
So if we have this potential, then 
\[ \frac{\partial}{\partial y}\left(\frac{\partial \varphi}{\partial x} \right) = \frac{\partial f}{\partial y}. \]
We also have by the other equation that 
\[ \frac{\partial}{\partial x}\left(\frac{\partial \varphi}{\partial y} \right) = \frac{\partial g}{\partial x}.\]
On the other hand, our theorem about mixed derivatives says that $D_1 D_2 = D_2 D_1$. Thus we come to a 
necessary condition for a potential to exist:
\[\frac{\partial g}{\partial x}=\frac{\partial f}{\partial y}\ (*).\]
This gives a quick test to determine whether a vector field \emph{does not} admit a potential. If the above
equation doesn't hold, then there is no possibility for a potential to exist. The converse is only
true under certain conditions. In other words, if you check the above condition and it holds, it's
still not certain that a potential exists.

\textbf{Example.} Let $F(x,y) = (x^2 y, \sin(xy))$. We can verify that $F$ does not admit a potential.



\end{document}
