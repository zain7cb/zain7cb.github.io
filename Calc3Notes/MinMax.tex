\documentclass{article}

\usepackage{amsmath, amsthm, amssymb, amsfonts}
\usepackage{thmtools}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{geometry}
\usepackage{float}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{framed}
\usepackage[dvipsnames]{xcolor}
\usepackage{tcolorbox}
\usepackage{physics}
\DeclareMathOperator{\grd}{grad}
\colorlet{LightGray}{White!90!Periwinkle}
\colorlet{LightOrange}{Orange!15}
\colorlet{LightGreen}{Green!15}

\newcommand{\HRule}[1]{\rule{\linewidth}{#1}}

\declaretheoremstyle[name=Theorem,]{thmsty}
\declaretheorem[style=thmsty,numberwithin=section]{theorem}
\tcolorboxenvironment{theorem}{colback=LightGray}

\declaretheoremstyle[name=Proposition,]{prosty}
\declaretheorem[style=prosty,numberlike=theorem]{proposition}
\tcolorboxenvironment{proposition}{colback=LightOrange}

\declaretheoremstyle[name=Principle,]{prcpsty}
\declaretheorem[style=prcpsty,numberlike=theorem]{principle}
\tcolorboxenvironment{principle}{colback=LightGreen}

\setstretch{1.2}
\geometry{
    textheight=9in,
    textwidth=5.5in,
    top=1in,
    headheight=12pt,
    headsep=25pt,
    footskip=30pt
}

% ------------------------------------------------------------------------------

\begin{document}

% ------------------------------------------------------------------------------
% Cover Page and ToC
% ------------------------------------------------------------------------------
\section*{Critical Points}

A point $P$ is a \textbf{critical point} of $f$ if $\grd f (P) = O$. 
Equivalently, all the partial derivatives $D_i f$ are $0$ at $P$.

\textbf{Example.} 
Find the critical points of $f(x,y) = e^{-(x^2+y^2)}$. We take 
partial derivatives and set them to $0$ to find the critical points.

As in the single variable case, we can have a variety of 
behaviors at a critical point; we do not necessarily have
a local minimum or local maximum.

Let $f$ be defined on an open set $U$. A point $P$ is called a
\textbf{local maximum} of $f$ if, in some
neighborhood $N$ of $P$, we have 
\[f(X) \leq f(P)\]
for all $X \in N$.

The concept of local minimum is defined similarly. 

\textbf{Theorem.} Let $f$ be a differentiable function on $U$.
Let $P$ be a local maximum. Then $P$ is a critical point of $f$.

The proof of this amounts to reducing it to a one variable problem.
If $H$ is a nonzero vector, and $t$ is small enough, then 
$P + tH \in U$. Moreover, if $t$ is small enough, $P+tH$ will land
in the neighborhood mentioned in the definition, so that
\[f(P+tH) \leq f(P)\]
for all $t$ in an interval of the form $(-\delta, \delta)$, $\delta > 0$.
So $g(t) = f(P+tH)$ has a local maximum at $t=0$. Thus $g'(t)=0$. 
By the chain rule, 
\[\grd f (P) \cdot H = 0.\]
This is true for all $H$, so we must have $\grd f (P) = 0$. $\blacksquare$

A similar argument shows that local minima are also critical points 
of $f$.

\section*{Boundary, Interior, etc.}

An \textbf{open ball} of radius $r>0$ in $\mathbb{R}^n$ centered at $P$ is defined to be 
the set of all points $X$ such that $\norm{X-P} < r$. 

A \textbf{closed ball} is similarly defined except $\norm{X-P} \leq r$ (rather than strict inequality).

A subset $U \subseteq \mathbb{R}^n$ is \textbf{open} if at every point $P \in U$, there is a ball of some radius around $P$
contained entirely in $U$.

An \textbf{interior point} $P$ of a set $S \subseteq \mathbb{R}^n$ is one such there exists a ball
of some radius around $P$ contained entirely in $S$. Thus one could rephrase the definition of openness
as each point being an interior point.

A point $P$ (not necessarily in $S$) is called a \textbf{boundary point} of $S$ if every open ball around 
$P$ contains both a point in $S$ and a point not in $S$.

A set is \textbf{closed} if it contains all of its boundary points.

A set is \textbf{bounded} if one can fit the set inside a ball. Equivalently, $S$ is bounded
if there is some $b>0$ such that $\norm{X} \leq b$ for all $X\in S$.

\textbf{Theorem.} Let $f$ be a continuous function defined on a closed and bounded set $S$. Then $f$
has a maximum and a minimum on $S$. 

The proof of this requires things out of the scope of this course.

One can see via examples that a continuous $f$ can fail to achieve extreme values if $S$ is not closed and bounded.
As an easy example, consider $f:(0,1)\to \mathbb{R}$, $f(x)=x$. 

In a general situation for some $f$ on a closed and bounded region $S$, we find the maxima and minima
by looking at the critical points in the interior of $S$. One must also look at the values of $f$ on the boundary,
however.

\textbf{Example.} Find the maxima and minima of $f(x,y) = x^3 + xy$ on the square with vertices
$(\pm 1, \pm 1)$. We do this by finding the critical points on the interior, and then also testing
the boundary points by parametrizing the four sides that make up the square and plugging those
parametrizations into $f$.

\textbf{Example.} Find the maximum of the function
\[f(x,y) = x^2 e^{-x^4-y^2}.\]

This function goes to $0$ as the distance from the origin goes
to $\infty$. This implies that the function indeed achieves a
maximum (as a result of the above theorem).

\end{document}